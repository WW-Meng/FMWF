{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b6bb0d-3cf0-468a-9f1e-a2b84ad7249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import pyautogui\n",
    "import random \n",
    "\n",
    "import os\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cc66aa-2246-4568-97c0-a1e7abf68309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tshark_thread(file_name, filt1, filt2, filt3, filt4, filt5):\n",
    "    # Start tshark to capture traffic for the given host filters\n",
    "    os.system(f'tshark -i 4 -w {file_name} -f \"(host {filt1}) or (host {filt2}) or (host {filt3}) or (host {filt4}) or (host {filt5})\"')\n",
    "    \n",
    "def visit_thread(url):\n",
    "    # Open Chrome browser and visit the provided URL\n",
    "    os.system('chrome --start-maximized ' + url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f731f5-1e11-45b8-b47d-b625fee43a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_path = '/chrome/5tab-url.csv' \n",
    "out_path = '/chrome/5tab-traffic/'\n",
    "\n",
    "\n",
    "count_url = 100\n",
    "count_repeat = 10\n",
    "count_batch = 10\n",
    "\n",
    "count = 0\n",
    "\n",
    "df_url = pd.read_csv(url_path, header=None)\n",
    "\n",
    "# Loop through the URLs in batches\n",
    "for C in range(0, int(count_url / count_batch)):\n",
    "\n",
    "    # Repeat the process for the specified number of times\n",
    "    for B in range(count_repeat):\n",
    "\n",
    "        # Iterate through the URLs in the current batch\n",
    "        for A in range(C * count_batch, C * count_batch + count_batch):\n",
    "            url1 = df_url.iloc[A, 1]\n",
    "            url2 = df_url.iloc[A, 3]\n",
    "            url3 = df_url.iloc[A, 5]\n",
    "            url4 = df_url.iloc[A, 7]\n",
    "            url5 = df_url.iloc[A, 9]\n",
    "                \n",
    "            web1 = int(df_url.iloc[A, 0])\n",
    "            web2 = int(df_url.iloc[A, 2])\n",
    "            web3 = int(df_url.iloc[A, 4])\n",
    "            web4 = int(df_url.iloc[A, 6])\n",
    "            web5 = int(df_url.iloc[A, 8])\n",
    "            \n",
    "            count += 1\n",
    "            print('\\r                                                             ', end='')\n",
    "            print('\\rcapturing:', A, '-', B, end='  ')\n",
    "            print(str(count) + '/' + str(count_url * count_repeat), end='  ')\n",
    "            print(url1, url2, url3, url4, url5, end='  ')\n",
    "\n",
    "            # Start traffic capture thread using tshark\n",
    "            t1 = threading.Thread(target=tshark_thread, \n",
    "                                  args=(out_path + f\"{web1}-{web2}-{web3}-{web4}-{web5}-{B}.pcap\", url1, url2, url3, url4, url5))\n",
    "            t1.start()\n",
    "            \n",
    "            # Random delay [0, 20) seconds before visiting the first website\n",
    "            time.sleep(random.uniform(0, 20))\n",
    "\n",
    "            # Start the thread to visit the first URL\n",
    "            t2 = threading.Thread(target=visit_thread, \n",
    "                                  args=(url1,))\n",
    "            t2.start()\n",
    "\n",
    "            # Random delay [0, 20) seconds before visiting the second website\n",
    "            time.sleep(random.uniform(0, 20))\n",
    "\n",
    "            # Start the thread to visit the second URL\n",
    "            t3 = threading.Thread(target=visit_thread, \n",
    "                                  args=(url2,))\n",
    "            t3.start()\n",
    "                 \n",
    "            # Random delay [0, 20) seconds before visiting the third website\n",
    "            time.sleep(random.uniform(0, 20))\n",
    "\n",
    "            # Start the thread to visit the third URL\n",
    "            t4 = threading.Thread(target=visit_thread, \n",
    "                                  args=(url3,))\n",
    "            t4.start()\n",
    "                    \n",
    "            # Random delay [0, 20) seconds before visiting the fourth website\n",
    "            time.sleep(random.uniform(0, 20))\n",
    "\n",
    "            # Start the thread to visit the fourth URL\n",
    "            t5 = threading.Thread(target=visit_thread, \n",
    "                                  args=(url4,))\n",
    "            t5.start()\n",
    "\n",
    "            # Random delay [0, 20) seconds before visiting the fifth website\n",
    "            time.sleep(random.uniform(0, 20))\n",
    "\n",
    "            # Start the thread to visit the fifth URL\n",
    "            t6 = threading.Thread(target=visit_thread, \n",
    "                                  args=(url5,))\n",
    "            t6.start()\n",
    "\n",
    "            # Wait for the pages to load\n",
    "            time.sleep(4)\n",
    "            loading_time = 0\n",
    "            while pyautogui.pixel(93, 63) == (71, 71, 71):  # Check if the page is still loading\n",
    "                time.sleep(1)\n",
    "                loading_time += 1\n",
    "                if loading_time >= 10:\n",
    "                    break\n",
    "\n",
    "            # Take a screenshot after the pages have loaded\n",
    "            time.sleep(2)\n",
    "            pyautogui.screenshot(out_path + f\"{web1}-{web2}-{web3}-{web4}-{web5}-{B}.jpg\")\n",
    "            time.sleep(1)\n",
    "\n",
    "            # Kill the tshark and Chrome processes to clean up\n",
    "            os.system('taskkill /F /IM tshark.exe')\n",
    "            os.system('taskkill /F /IM chrome.exe')\n",
    "\n",
    "            time.sleep(4)\n",
    "    \n",
    "print('\\ndone!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6200b8be-f2a9-4c19-a2ff-2eabda17b433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c42906-f4da-458e-a55f-e949907b5fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21537d83-314c-420a-8cd5-f626905e457a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After an exception interrupts the program, execute this code before re-executing the program\n",
    "import os\n",
    "os.system('taskkill /F /IM chrome.exe')\n",
    "os.system('taskkill /F /IM tshark.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ec9664-4a04-4c38-845a-bce675fb2706",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
